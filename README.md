[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2022.10.11

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#Prompt>Prompt</a></li>
  </ol>
</details>

## Prompt

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2022-10-10**|**CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation**|Tanay Dixit et.al.|[2210.04873v1](http://arxiv.org/abs/2210.04873v1)|**[link](https://github.com/tanay2001/core)**|
|**2022-10-10**|**FS-DETR: Few-Shot DEtection TRansformer with prompting and without re-training**|Adrian Bulat et.al.|[2210.04845v1](http://arxiv.org/abs/2210.04845v1)|null|
|**2022-10-10**|**Visual Prompt Tuning for Test-time Domain Adaptation**|Yunhe Gao et.al.|[2210.04831v1](http://arxiv.org/abs/2210.04831v1)|null|
|**2022-10-10**|**Knowledge Prompts: Injecting World Knowledge into Language Models through Soft Prompts**|Cicero Nogueira dos Santos et.al.|[2210.04726v1](http://arxiv.org/abs/2210.04726v1)|null|
|**2022-10-10**|**Language Models Are Poor Learners of Directional Inference**|Tianyi Li et.al.|[2210.04695v1](http://arxiv.org/abs/2210.04695v1)|**[link](https://github.com/teddy-li/lm-dirctionalinference)**|
|**2022-10-10**|**XPrompt: Exploring the Extreme of Prompt Tuning**|Fang Ma et.al.|[2210.04457v1](http://arxiv.org/abs/2210.04457v1)|null|
|**2022-10-09**|**Recent ALICE results on quarkonium production in nuclear collisions**|Biswarup Paul et.al.|[2210.04356v1](http://arxiv.org/abs/2210.04356v1)|null|
|**2022-10-09**|**ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models**|Jiannan Xiang et.al.|[2210.04325v1](http://arxiv.org/abs/2210.04325v1)|**[link](https://github.com/szxiangjn/any-shot-data2text)**|
|**2022-10-09**|**Learning to Decompose Visual Features with Latent Textual Prompts**|Feng Wang et.al.|[2210.04287v1](http://arxiv.org/abs/2210.04287v1)|null|
|**2022-10-09**|**On some features of the solar proton event on 2021 October 28 (GLE73)**|I. M. Chertok et.al.|[2210.04238v1](http://arxiv.org/abs/2210.04238v1)|null|
|**2022-10-07**|**SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based Speech-Text Pre-training**|Ziqiang Zhang et.al.|[2210.03730v1](http://arxiv.org/abs/2210.03730v1)|**[link](https://github.com/microsoft/speecht5)**|
|**2022-10-07**|**Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts**|Nghia T. Le et.al.|[2210.03690v1](http://arxiv.org/abs/2210.03690v1)|null|
|**2022-10-07**|**Automatic Chain of Thought Prompting in Large Language Models**|Zhuosheng Zhang et.al.|[2210.03493v1](http://arxiv.org/abs/2210.03493v1)|**[link](https://github.com/amazon-research/auto-cot)**|
|**2022-10-07**|**Measuring and Narrowing the Compositionality Gap in Language Models**|Ofir Press et.al.|[2210.03350v1](http://arxiv.org/abs/2210.03350v1)|**[link](https://github.com/ofirpress/self-ask)**|
|**2022-10-07**|**Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**|Kenton Lee et.al.|[2210.03347v1](http://arxiv.org/abs/2210.03347v1)|null|
|**2022-10-07**|**A Unified Framework for Multi-intent Spoken Language Understanding with prompting**|Feifan Song et.al.|[2210.03337v1](http://arxiv.org/abs/2210.03337v1)|null|
|**2022-10-07**|**Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**|Zhichao Yang et.al.|[2210.03304v1](http://arxiv.org/abs/2210.03304v1)|**[link](https://github.com/whaleloops/KEPT)**|
|**2022-10-06**|**Small Character Models Match Large Word Models for Autocomplete Under Memory Constraints**|Ganesh Jawahar et.al.|[2210.03251v1](http://arxiv.org/abs/2210.03251v1)|null|
|**2022-10-06**|**Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models**|David Wingate et.al.|[2210.03162v1](http://arxiv.org/abs/2210.03162v1)|null|
|**2022-10-06**|**MaPLe: Multi-modal Prompt Learning**|Muhammad Uzair Khattak et.al.|[2210.03117v1](http://arxiv.org/abs/2210.03117v1)|**[link](https://github.com/muzairkhattak/multimodal-prompt-learning)**|
|**2022-10-06**|**CLIP model is an Efficient Continual Learner**|Vishal Thengane et.al.|[2210.03114v1](http://arxiv.org/abs/2210.03114v1)|**[link](https://github.com/vgthengane/continual-clip)**|
|**2022-10-06**|**VIMA: General Robot Manipulation with Multimodal Prompts**|Yunfan Jiang et.al.|[2210.03094v1](http://arxiv.org/abs/2210.03094v1)|null|
|**2022-10-06**|**Language Models are Multilingual Chain-of-Thought Reasoners**|Freda Shi et.al.|[2210.03057v1](http://arxiv.org/abs/2210.03057v1)|**[link](https://github.com/google-research/url-nlp)**|
|**2022-10-06**|**Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization**|Seonghyeon Ye et.al.|[2210.03029v1](http://arxiv.org/abs/2210.03029v1)|**[link](https://github.com/seonghyeonye/rospr)**|
|**2022-10-06**|**Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation**|Xu Guo et.al.|[2210.02952v1](http://arxiv.org/abs/2210.02952v1)|null|
|**2022-10-06**|**Spatial segregation of substitutional B atoms in graphene patterned by the moir√© superlattice on Ir(111)**|Marc G. Cuxart et.al.|[2210.02902v1](http://arxiv.org/abs/2210.02902v1)|null|
|**2022-10-06**|**Binding Language Models in Symbolic Languages**|Zhoujun Cheng et.al.|[2210.02875v1](http://arxiv.org/abs/2210.02875v1)|**[link](https://github.com/hkunlp/binder)**|
|**2022-10-06**|**Distilling Task-specific Logical Rules from Large Pre-trained Models**|Tao Chen et.al.|[2210.02768v1](http://arxiv.org/abs/2210.02768v1)|null|
|**2022-10-06**|**Rapid reconstruction of compact binary sources using meshfree approximation**|Lalit Pathak et.al.|[2210.02706v1](http://arxiv.org/abs/2210.02706v1)|null|

<p align=right>(<a href=#Updated-on-20221011>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

