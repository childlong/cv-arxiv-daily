---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2022.10.21

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#Prompt>Prompt</a></li>
  </ol>
</details>

## Prompt

| Publish Date | Title | Authors | PDF | Code |
|:---------|:-----------------------|:---------|:------|:------|
|**2022-10-19**|**TabLLM: Few-shot Classification of Tabular Data with Large Language Models**|Stefan Hegselmann et.al.|[2210.10723v1](http://arxiv.org/abs/2210.10723v1)|null|
|**2022-10-19**|**Schema-aware Reference as Prompt Improves Data-Efficient Relational Triple and Event Extraction**|Yunzhi Yao et.al.|[2210.10709v1](http://arxiv.org/abs/2210.10709v1)|**[link](https://github.com/zjunlp/RAP)**|
|**2022-10-19**|**Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study**|Xin Xu et.al.|[2210.10678v1](http://arxiv.org/abs/2210.10678v1)|**[link](https://github.com/zjunlp/lrebench)**|
|**2022-10-19**|**DALLE-2 is Seeing Double: Flaws in Word-to-Concept Mapping in Text2Image Models**|Royi Rassin et.al.|[2210.10606v1](http://arxiv.org/abs/2210.10606v1)|null|
|**2022-10-19**|**Language Does More Than Describe: On The Lack Of Figurative Speech in Text-To-Image Models**|Ricardo Kleinlein et.al.|[2210.10578v1](http://arxiv.org/abs/2210.10578v1)|null|
|**2022-10-19**|**Hybrid-Regressive Neural Machine Translation**|Qiang Wang et.al.|[2210.10416v1](http://arxiv.org/abs/2210.10416v1)|null|
|**2022-10-19**|**CPL: Counterfactual Prompt Learning for Vision and Language Models**|Xuehai He et.al.|[2210.10362v1](http://arxiv.org/abs/2210.10362v1)|null|
|**2022-10-19**|**Continued Pretraining for Better Zero- and Few-Shot Promptability**|Zhaofeng Wu et.al.|[2210.10258v1](http://arxiv.org/abs/2210.10258v1)|null|
|**2022-10-18**|**Finding high-redshift gamma-ray bursts in tandem near-infrared and optical surveys**|S. Campana et.al.|[2210.09749v1](http://arxiv.org/abs/2210.09749v1)|null|
|**2022-10-18**|**DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation**|Hanqing Zhang et.al.|[2210.09551v1](http://arxiv.org/abs/2210.09551v1)|**[link](https://github.com/littlehacker26/discriminator-cooperative-unlikelihood-prompt-tuning)**|
|**2022-10-18**|**Systematicity in GPT-3's Interpretation of Novel English Noun Compounds**|Siyan Li et.al.|[2210.09492v1](http://arxiv.org/abs/2210.09492v1)|null|
|**2022-10-17**|**Using Bottleneck Adapters to Identify Cancer in Clinical Notes under Low-Resource Constraints**|Omid Rohanian et.al.|[2210.09440v1](http://arxiv.org/abs/2210.09440v1)|null|
|**2022-10-17**|**Heavy Neutral Leptons at the Electron-Ion Collider**|Brian Batell et.al.|[2210.09287v1](http://arxiv.org/abs/2210.09287v1)|null|
|**2022-10-17**|**Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve Them**|Mirac Suzgun et.al.|[2210.09261v1](http://arxiv.org/abs/2210.09261v1)|**[link](https://github.com/suzgunmirac/big-bench-hard)**|
|**2022-10-17**|**Prompting GPT-3 To Be Reliable**|Chenglei Si et.al.|[2210.09150v1](http://arxiv.org/abs/2210.09150v1)|**[link](https://github.com/noviscl/gpt3-reliability)**|
|**2022-10-16**|**Data-Efficient Pipeline for Offline Reinforcement Learning with Limited Data**|Allen Nie et.al.|[2210.08642v1](http://arxiv.org/abs/2210.08642v1)|null|
|**2022-10-16**|**Perceptual-Score: A Psychophysical Measure for Assessing the Biological Plausibility of Visual Recognition Models**|Brandon RichardWebster et.al.|[2210.08632v1](http://arxiv.org/abs/2210.08632v1)|null|
|**2022-10-16**|**NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly**|Yi R. Fung et.al.|[2210.08604v1](http://arxiv.org/abs/2210.08604v1)|null|
|**2022-10-16**|**On $\mathcal{I}$-covering images of metric spaces**|Xiangeng Zhou et.al.|[2210.08544v1](http://arxiv.org/abs/2210.08544v1)|null|
|**2022-10-16**|**Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding**|Jianing Wang et.al.|[2210.08536v1](http://arxiv.org/abs/2210.08536v1)|null|
|**2022-10-15**|**Improving Radiology Summarization with Radiograph and Anatomy Prompts**|Jinpeng Hu et.al.|[2210.08303v1](http://arxiv.org/abs/2210.08303v1)|null|
|**2022-10-14**|**MiQA: A Benchmark for Inference on Metaphorical Questions**|Iulia-Maria Comsa et.al.|[2210.07993v1](http://arxiv.org/abs/2210.07993v1)|null|
|**2022-10-14**|**The Possible Cause of the 40 SpaceX Starlink Satellite Losses in February 2022: Prompt Penetrating Electric Fields and the Dayside Equatorial and Midlatitude Ionospheric Convective Uplift**|Bruce T. Tsurutani et.al.|[2210.07902v1](http://arxiv.org/abs/2210.07902v1)|null|
|**2022-10-17**|**One Model to Edit Them All: Free-Form Text-Driven Image Manipulation with Semantic Modulations**|Yiming Zhu et.al.|[2210.07883v2](http://arxiv.org/abs/2210.07883v2)|**[link](https://github.com/kumapowerliu/ffclip)**|
|**2022-10-14**|**Robust Preference Learning for Storytelling via Contrastive Reinforcement Learning**|Louis Castricato et.al.|[2210.07792v1](http://arxiv.org/abs/2210.07792v1)|null|
|**2022-10-14**|**Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue**|Yingxiu Zhao et.al.|[2210.07783v1](http://arxiv.org/abs/2210.07783v1)|null|
|**2022-10-14**|**Language Generation Models Can Cause Harm: So What Can We Do About It? An Actionable Survey**|Sachin Kumar et.al.|[2210.07700v1](http://arxiv.org/abs/2210.07700v1)|null|
|**2022-10-14**|**Enabling Classifiers to Make Judgements Explicitly Aligned with Human Values**|Yejin Bang et.al.|[2210.07652v1](http://arxiv.org/abs/2210.07652v1)|null|
|**2022-10-14**|**Multi-Task Pre-Training of Modular Prompt for Few-Shot Learning**|Tianxiang Sun et.al.|[2210.07565v1](http://arxiv.org/abs/2210.07565v1)|null|
|**2022-10-13**|**Bootstrapping Multilingual Semantic Parsers using Large Language Models**|Abhijeet Awasthi et.al.|[2210.07313v1](http://arxiv.org/abs/2210.07313v1)|null|
|**2022-10-13**|**Joint Reasoning on Hybrid-knowledge sources for Task-Oriented Dialog**|Mayank Mishra et.al.|[2210.07295v1](http://arxiv.org/abs/2210.07295v1)|null|
|**2022-10-13**|**Language Model Decoding as Likelihood-Utility Alignment**|Martin Josifoski et.al.|[2210.07228v1](http://arxiv.org/abs/2210.07228v1)|null|
|**2022-10-13**|**Unified Vision and Language Prompt Learning**|Yuhang Zang et.al.|[2210.07225v1](http://arxiv.org/abs/2210.07225v1)|**[link](https://github.com/yuhangzang/upt)**|
|**2022-10-13**|**MAPL: Parameter-Efficient Adaptation of Unimodal Pre-Trained Models for Vision-Language Few-Shot Prompting**|Oscar Mañas et.al.|[2210.07179v1](http://arxiv.org/abs/2210.07179v1)|null|
|**2022-10-13**|**Patterns of Structural Reflection in the large-cardinal hierarchy**|Joan Bagaria et.al.|[2210.07120v1](http://arxiv.org/abs/2210.07120v1)|null|
|**2022-10-13**|**Scaling Back-Translation with Domain Text Generation for Sign Language Gloss Translation**|Jinhui Ye et.al.|[2210.07054v1](http://arxiv.org/abs/2210.07054v1)|**[link](https://github.com/atrewin/pgen)**|
|**2022-10-13**|**Prompt-based Connective Prediction Method for Fine-grained Implicit Discourse Relation Recognition**|Hao Zhou et.al.|[2210.07032v1](http://arxiv.org/abs/2210.07032v1)|**[link](https://github.com/zh-i9/pcp-for-idrr)**|
|**2022-10-13**|**DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image Diffusion Models**|Zeyang Sha et.al.|[2210.06998v1](http://arxiv.org/abs/2210.06998v1)|null|
|**2022-10-13**|**Feature-Proxy Transformer for Few-Shot Segmentation**|Jian-Wei Zhang et.al.|[2210.06908v1](http://arxiv.org/abs/2210.06908v1)|**[link](https://github.com/jarvis73/fptrans)**|
|**2022-10-13**|**Re3: Generating Longer Stories With Recursive Reprompting and Revision**|Kevin Yang et.al.|[2210.06774v1](http://arxiv.org/abs/2210.06774v1)|**[link](https://github.com/yangkevin2/emnlp22-re3-story-generation)**|
|**2022-10-13**|**Explanations from Large Language Models Make Small Reasoners Better**|Shiyang Li et.al.|[2210.06726v1](http://arxiv.org/abs/2210.06726v1)|null|
|**2022-10-12**|**Prompt Generation Networks for Efficient Adaptation of Frozen Vision Transformers**|Jochem Loedeman et.al.|[2210.06466v1](http://arxiv.org/abs/2210.06466v1)|**[link](https://github.com/jochemloedeman/pgn)**|
|**2022-10-12**|**Probing Commonsense Knowledge in Pre-trained Language Models with Sense-level Precision and Expanded Vocabulary**|Daniel Loureiro et.al.|[2210.06376v1](http://arxiv.org/abs/2210.06376v1)|**[link](https://github.com/danlou/synbert)**|
|**2022-10-12**|**Context Generation Improves Open Domain Question Answering**|Dan Su et.al.|[2210.06349v1](http://arxiv.org/abs/2210.06349v1)|null|
|**2022-10-12**|**Visual Prompting for Adversarial Robustness**|Aochuan Chen et.al.|[2210.06284v1](http://arxiv.org/abs/2210.06284v1)|null|
|**2022-10-12**|**Towards visually prompted keyword localisation for zero-resource spoken languages**|Leanne Nortje et.al.|[2210.06229v1](http://arxiv.org/abs/2210.06229v1)|null|
|**2022-10-12**|**Zero-Shot Prompting for Implicit Intent Prediction and Recommendation with Commonsense Reasoning**|Hui-Chi Kuo et.al.|[2210.05901v1](http://arxiv.org/abs/2210.05901v1)|null|
|**2022-10-11**|**CLIP also Understands Text: Prompting CLIP for Phrase Understanding**|An Yan et.al.|[2210.05836v1](http://arxiv.org/abs/2210.05836v1)|null|
|**2022-10-11**|**Understanding or Manipulation: Rethinking Online Performance Gains of Modern Recommender Systems**|Zhengbang Zhu et.al.|[2210.05662v1](http://arxiv.org/abs/2210.05662v1)|null|
|**2022-10-11**|**A Kernel-Based View of Language Model Fine-Tuning**|Sadhika Malladi et.al.|[2210.05643v1](http://arxiv.org/abs/2210.05643v1)|**[link](https://github.com/princeton-nlp/lm-kernel-ft)**|
|**2022-10-11**|**Rethinking the Event Coding Pipeline with Prompt Entailment**|Clément Lefebvre et.al.|[2210.05257v1](http://arxiv.org/abs/2210.05257v1)|**[link](https://github.com/clement-lef/pr-ent)**|
|**2022-10-11**|**Can Language Models Be Specific? How?**|Jie Huang et.al.|[2210.05159v1](http://arxiv.org/abs/2210.05159v1)|null|
|**2022-10-10**|**REV: Information-Theoretic Evaluation of Free-Text Rationales**|Hanjie Chen et.al.|[2210.04982v1](http://arxiv.org/abs/2210.04982v1)|null|
|**2022-10-10**|**CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation**|Tanay Dixit et.al.|[2210.04873v1](http://arxiv.org/abs/2210.04873v1)|**[link](https://github.com/tanay2001/core)**|
|**2022-10-10**|**FS-DETR: Few-Shot DEtection TRansformer with prompting and without re-training**|Adrian Bulat et.al.|[2210.04845v1](http://arxiv.org/abs/2210.04845v1)|null|
|**2022-10-10**|**Visual Prompt Tuning for Test-time Domain Adaptation**|Yunhe Gao et.al.|[2210.04831v1](http://arxiv.org/abs/2210.04831v1)|null|
|**2022-10-10**|**Knowledge Prompts: Injecting World Knowledge into Language Models through Soft Prompts**|Cicero Nogueira dos Santos et.al.|[2210.04726v1](http://arxiv.org/abs/2210.04726v1)|null|
|**2022-10-10**|**Language Models Are Poor Learners of Directional Inference**|Tianyi Li et.al.|[2210.04695v1](http://arxiv.org/abs/2210.04695v1)|**[link](https://github.com/teddy-li/lm-dirctionalinference)**|
|**2022-10-10**|**XPrompt: Exploring the Extreme of Prompt Tuning**|Fang Ma et.al.|[2210.04457v1](http://arxiv.org/abs/2210.04457v1)|null|
|**2022-10-09**|**Recent ALICE results on quarkonium production in nuclear collisions**|Biswarup Paul et.al.|[2210.04356v1](http://arxiv.org/abs/2210.04356v1)|null|
|**2022-10-11**|**ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models**|Jiannan Xiang et.al.|[2210.04325v2](http://arxiv.org/abs/2210.04325v2)|**[link](https://github.com/szxiangjn/any-shot-data2text)**|
|**2022-10-09**|**Learning to Decompose Visual Features with Latent Textual Prompts**|Feng Wang et.al.|[2210.04287v1](http://arxiv.org/abs/2210.04287v1)|null|
|**2022-10-09**|**On some features of the solar proton event on 2021 October 28 (GLE73)**|I. M. Chertok et.al.|[2210.04238v1](http://arxiv.org/abs/2210.04238v1)|null|
|**2022-10-07**|**SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based Speech-Text Pre-training**|Ziqiang Zhang et.al.|[2210.03730v1](http://arxiv.org/abs/2210.03730v1)|**[link](https://github.com/microsoft/speecht5)**|
|**2022-10-07**|**Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts**|Nghia T. Le et.al.|[2210.03690v1](http://arxiv.org/abs/2210.03690v1)|null|
|**2022-10-07**|**Automatic Chain of Thought Prompting in Large Language Models**|Zhuosheng Zhang et.al.|[2210.03493v1](http://arxiv.org/abs/2210.03493v1)|**[link](https://github.com/amazon-research/auto-cot)**|
|**2022-10-07**|**Measuring and Narrowing the Compositionality Gap in Language Models**|Ofir Press et.al.|[2210.03350v1](http://arxiv.org/abs/2210.03350v1)|**[link](https://github.com/ofirpress/self-ask)**|
|**2022-10-07**|**Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**|Kenton Lee et.al.|[2210.03347v1](http://arxiv.org/abs/2210.03347v1)|null|
|**2022-10-07**|**A Unified Framework for Multi-intent Spoken Language Understanding with prompting**|Feifan Song et.al.|[2210.03337v1](http://arxiv.org/abs/2210.03337v1)|null|
|**2022-10-07**|**Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**|Zhichao Yang et.al.|[2210.03304v1](http://arxiv.org/abs/2210.03304v1)|**[link](https://github.com/whaleloops/KEPT)**|
|**2022-10-06**|**Small Character Models Match Large Word Models for Autocomplete Under Memory Constraints**|Ganesh Jawahar et.al.|[2210.03251v1](http://arxiv.org/abs/2210.03251v1)|null|
|**2022-10-06**|**Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models**|David Wingate et.al.|[2210.03162v1](http://arxiv.org/abs/2210.03162v1)|null|
|**2022-10-06**|**MaPLe: Multi-modal Prompt Learning**|Muhammad Uzair Khattak et.al.|[2210.03117v1](http://arxiv.org/abs/2210.03117v1)|**[link](https://github.com/muzairkhattak/multimodal-prompt-learning)**|
|**2022-10-06**|**CLIP model is an Efficient Continual Learner**|Vishal Thengane et.al.|[2210.03114v1](http://arxiv.org/abs/2210.03114v1)|**[link](https://github.com/vgthengane/continual-clip)**|
|**2022-10-06**|**VIMA: General Robot Manipulation with Multimodal Prompts**|Yunfan Jiang et.al.|[2210.03094v1](http://arxiv.org/abs/2210.03094v1)|null|
|**2022-10-06**|**Language Models are Multilingual Chain-of-Thought Reasoners**|Freda Shi et.al.|[2210.03057v1](http://arxiv.org/abs/2210.03057v1)|**[link](https://github.com/google-research/url-nlp)**|
|**2022-10-06**|**Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization**|Seonghyeon Ye et.al.|[2210.03029v1](http://arxiv.org/abs/2210.03029v1)|**[link](https://github.com/seonghyeonye/rospr)**|
|**2022-10-06**|**Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation**|Xu Guo et.al.|[2210.02952v1](http://arxiv.org/abs/2210.02952v1)|null|
|**2022-10-06**|**Spatial segregation of substitutional B atoms in graphene patterned by the moiré superlattice on Ir(111)**|Marc G. Cuxart et.al.|[2210.02902v1](http://arxiv.org/abs/2210.02902v1)|null|
|**2022-10-06**|**Binding Language Models in Symbolic Languages**|Zhoujun Cheng et.al.|[2210.02875v1](http://arxiv.org/abs/2210.02875v1)|**[link](https://github.com/hkunlp/binder)**|
|**2022-10-06**|**Distilling Task-specific Logical Rules from Large Pre-trained Models**|Tao Chen et.al.|[2210.02768v1](http://arxiv.org/abs/2210.02768v1)|null|
|**2022-10-06**|**Rapid reconstruction of compact binary sources using meshfree approximation**|Lalit Pathak et.al.|[2210.02706v1](http://arxiv.org/abs/2210.02706v1)|null|

<p align=right>(<a href=#Updated-on-20221021>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

