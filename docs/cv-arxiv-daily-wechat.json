{"OVOD": {}, "OV": {}, "Prompt": {"2210.03117": "- 2022-10-06, **MaPLe: Multi-modal Prompt Learning**, Muhammad Uzair Khattak et.al., Paper: [http://arxiv.org/abs/2210.03117v1](http://arxiv.org/abs/2210.03117v1), Code: **[https://github.com/muzairkhattak/multimodal-prompt-learning](https://github.com/muzairkhattak/multimodal-prompt-learning)**\n", "2210.03114": "- 2022-10-06, **CLIP model is an Efficient Continual Learner**, Vishal Thengane et.al., Paper: [http://arxiv.org/abs/2210.03114v1](http://arxiv.org/abs/2210.03114v1), Code: **[https://github.com/vgthengane/continual-clip](https://github.com/vgthengane/continual-clip)**\n", "2210.03094": "- 2022-10-06, **VIMA: General Robot Manipulation with Multimodal Prompts**, Yunfan Jiang et.al., Paper: [http://arxiv.org/abs/2210.03094v1](http://arxiv.org/abs/2210.03094v1)\n", "2210.03057": "- 2022-10-06, **Language Models are Multilingual Chain-of-Thought Reasoners**, Freda Shi et.al., Paper: [http://arxiv.org/abs/2210.03057v1](http://arxiv.org/abs/2210.03057v1), Code: **[https://github.com/google-research/url-nlp](https://github.com/google-research/url-nlp)**\n", "2210.03029": "- 2022-10-06, **Retrieval of Soft Prompt Enhances Zero-Shot Task Generalization**, Seonghyeon Ye et.al., Paper: [http://arxiv.org/abs/2210.03029v1](http://arxiv.org/abs/2210.03029v1), Code: **[https://github.com/seonghyeonye/rospr](https://github.com/seonghyeonye/rospr)**\n", "2210.02952": "- 2022-10-06, **Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation**, Xu Guo et.al., Paper: [http://arxiv.org/abs/2210.02952v1](http://arxiv.org/abs/2210.02952v1)\n", "2210.02902": "- 2022-10-06, **Spatial segregation of substitutional B atoms in graphene patterned by the moir\u00e9 superlattice on Ir(111)**, Marc G. Cuxart et.al., Paper: [http://arxiv.org/abs/2210.02902v1](http://arxiv.org/abs/2210.02902v1)\n", "2210.02875": "- 2022-10-06, **Binding Language Models in Symbolic Languages**, Zhoujun Cheng et.al., Paper: [http://arxiv.org/abs/2210.02875v1](http://arxiv.org/abs/2210.02875v1), Code: **[https://github.com/hkunlp/binder](https://github.com/hkunlp/binder)**\n", "2210.02768": "- 2022-10-06, **Distilling Task-specific Logical Rules from Large Pre-trained Models**, Tao Chen et.al., Paper: [http://arxiv.org/abs/2210.02768v1](http://arxiv.org/abs/2210.02768v1)\n", "2210.02706": "- 2022-10-06, **Rapid reconstruction of compact binary sources using meshfree approximation**, Lalit Pathak et.al., Paper: [http://arxiv.org/abs/2210.02706v1](http://arxiv.org/abs/2210.02706v1)\n", "2210.03730": "- 2022-10-07, **SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based Speech-Text Pre-training**, Ziqiang Zhang et.al., Paper: [http://arxiv.org/abs/2210.03730v1](http://arxiv.org/abs/2210.03730v1), Code: **[https://github.com/microsoft/speecht5](https://github.com/microsoft/speecht5)**\n", "2210.03690": "- 2022-10-07, **Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts**, Nghia T. Le et.al., Paper: [http://arxiv.org/abs/2210.03690v1](http://arxiv.org/abs/2210.03690v1)\n", "2210.03493": "- 2022-10-07, **Automatic Chain of Thought Prompting in Large Language Models**, Zhuosheng Zhang et.al., Paper: [http://arxiv.org/abs/2210.03493v1](http://arxiv.org/abs/2210.03493v1), Code: **[https://github.com/amazon-research/auto-cot](https://github.com/amazon-research/auto-cot)**\n", "2210.03350": "- 2022-10-07, **Measuring and Narrowing the Compositionality Gap in Language Models**, Ofir Press et.al., Paper: [http://arxiv.org/abs/2210.03350v1](http://arxiv.org/abs/2210.03350v1), Code: **[https://github.com/ofirpress/self-ask](https://github.com/ofirpress/self-ask)**\n", "2210.03347": "- 2022-10-07, **Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding**, Kenton Lee et.al., Paper: [http://arxiv.org/abs/2210.03347v1](http://arxiv.org/abs/2210.03347v1)\n", "2210.03337": "- 2022-10-07, **A Unified Framework for Multi-intent Spoken Language Understanding with prompting**, Feifan Song et.al., Paper: [http://arxiv.org/abs/2210.03337v1](http://arxiv.org/abs/2210.03337v1)\n", "2210.03304": "- 2022-10-07, **Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding**, Zhichao Yang et.al., Paper: [http://arxiv.org/abs/2210.03304v1](http://arxiv.org/abs/2210.03304v1), Code: **[https://github.com/whaleloops/KEPT](https://github.com/whaleloops/KEPT)**\n", "2210.03251": "- 2022-10-06, **Small Character Models Match Large Word Models for Autocomplete Under Memory Constraints**, Ganesh Jawahar et.al., Paper: [http://arxiv.org/abs/2210.03251v1](http://arxiv.org/abs/2210.03251v1)\n", "2210.03162": "- 2022-10-06, **Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models**, David Wingate et.al., Paper: [http://arxiv.org/abs/2210.03162v1](http://arxiv.org/abs/2210.03162v1)\n", "2210.04873": "- 2022-10-10, **CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation**, Tanay Dixit et.al., Paper: [http://arxiv.org/abs/2210.04873v1](http://arxiv.org/abs/2210.04873v1), Code: **[https://github.com/tanay2001/core](https://github.com/tanay2001/core)**\n", "2210.04845": "- 2022-10-10, **FS-DETR: Few-Shot DEtection TRansformer with prompting and without re-training**, Adrian Bulat et.al., Paper: [http://arxiv.org/abs/2210.04845v1](http://arxiv.org/abs/2210.04845v1)\n", "2210.04831": "- 2022-10-10, **Visual Prompt Tuning for Test-time Domain Adaptation**, Yunhe Gao et.al., Paper: [http://arxiv.org/abs/2210.04831v1](http://arxiv.org/abs/2210.04831v1)\n", "2210.04726": "- 2022-10-10, **Knowledge Prompts: Injecting World Knowledge into Language Models through Soft Prompts**, Cicero Nogueira dos Santos et.al., Paper: [http://arxiv.org/abs/2210.04726v1](http://arxiv.org/abs/2210.04726v1)\n", "2210.04695": "- 2022-10-10, **Language Models Are Poor Learners of Directional Inference**, Tianyi Li et.al., Paper: [http://arxiv.org/abs/2210.04695v1](http://arxiv.org/abs/2210.04695v1), Code: **[https://github.com/teddy-li/lm-dirctionalinference](https://github.com/teddy-li/lm-dirctionalinference)**\n", "2210.04457": "- 2022-10-10, **XPrompt: Exploring the Extreme of Prompt Tuning**, Fang Ma et.al., Paper: [http://arxiv.org/abs/2210.04457v1](http://arxiv.org/abs/2210.04457v1)\n", "2210.04356": "- 2022-10-09, **Recent ALICE results on quarkonium production in nuclear collisions**, Biswarup Paul et.al., Paper: [http://arxiv.org/abs/2210.04356v1](http://arxiv.org/abs/2210.04356v1)\n", "2210.04325": "- 2022-10-11, **ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models**, Jiannan Xiang et.al., Paper: [http://arxiv.org/abs/2210.04325v2](http://arxiv.org/abs/2210.04325v2), Code: **[https://github.com/szxiangjn/any-shot-data2text](https://github.com/szxiangjn/any-shot-data2text)**\n", "2210.04287": "- 2022-10-09, **Learning to Decompose Visual Features with Latent Textual Prompts**, Feng Wang et.al., Paper: [http://arxiv.org/abs/2210.04287v1](http://arxiv.org/abs/2210.04287v1)\n", "2210.04238": "- 2022-10-09, **On some features of the solar proton event on 2021 October 28 (GLE73)**, I. M. Chertok et.al., Paper: [http://arxiv.org/abs/2210.04238v1](http://arxiv.org/abs/2210.04238v1)\n"}, "OpenVocabularyOD": {}, "OpenVocabulary": {}}